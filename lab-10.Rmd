---
title: "Lab 10 - Grading the professor, Pt. 2"
author: "Benjamin Egan"
date: "3/25/2025"
output: github_document
---

This is the link to the assignment page (https://datascience4psych.github.io/DataScience4Psych/lab10.html). This includes the relevant information for the assignment alongside required questions I needed to answer.

```{r load-packages, message=FALSE, echo = FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
```

## Simple Linear Regression


```{r simple regression}
view(evals)

m_bty <- lm(score ~ bty_avg, data = evals)

summary(m_bty)

```

Linear Model: y = 3.88 + .067x
R-squared: .035
Adjusted R-squared: .033

## Multiple Linear Regression

```{r Q2}

m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)

summary(m_bty_gen)

```

Linear model: y = 3.747 + .074(bty_avg) + .172(gender)
R-squared: .059
Adjusted R-squared: .055

#### Interpretation

intercept: A female with an average beauty rating of zero will get an evaluation of 3.7

bty_avg slope: For people of the same gender, increasing their average beauty rating by one will only increase their evaluation score by .07

gender slope: A male will have .172 higher eval score than a female with the same average beauty rating.

#### Questions 4-9

4. This model (m_bty_gen) accounts for 5.5% of the variance in score

5. For males: y = 3.747 + .074(bty_avg) + .172

6. Males will tend to have the higher beauty rating compared to females

7. Males have a slightly higher evaluation score (.172) than females for the same beauty rating.

8. m_bty r-squared of .033 versus m_bty_gen r-squared of .055. Adding gender to the model only accounts for an additional 2.2% of the variance of score. I would say adding it made little difference in explaining evaluation scores.

9. .067 bty_avg slope for the original model. .074 bty_avg slope for the model with gender. Adding gender meant that beauty rating of professor had a slightly increased  "weight" for predicting score.

### Replacing gender with rank

```{r add in rank to original}

m_bty_rank <- lm(score ~ bty_avg + rank, data = evals)

summary(m_bty_rank)

```

Linear model: y = 3.982 + .068(bty_avg) - .161(tenure track)
Linear model: y = 3.982 + .068(bty_avg) - .126(tenured)

R-squared: .047
Adjusted R-squared: .040

#### Interpretation

intercept: A teaching professor with an average beauty rating of zero will get an evaluation of 3.98

bty_avg slope: For people of the same rank, increasing their average beauty rating by one will only increase their evaluation score by .068

tenure track slope: A tenure track professor will have a .161 lower eval score than a teaching professor with the same average beauty rating.

tenured slope: A tenured professor will have a .126 lower eval score than a teaching professor with the same average beauty rating.


## Finding the best model

Going forward, I will only consider the following variables as potential predictors: rank, ethnicity, gender, language, age, cls_perc_eval, cls_did_eval, cls_students, cls_level, cls_profs, cls_credits, bty_avg.

11. Based on the predictors above, I would guess ethinicity would be the worst predictors.

```


language, cls_perc_eval (percent students completed), cls_did_eval (number students completed) would be good predictors of evaluation.
